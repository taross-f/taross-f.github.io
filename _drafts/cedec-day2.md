## 人工知能（メタAI）を用いたゲームデザインの変革

#### メタAIの背景
ジレンマ

ルール
クリア条件だけじゃない、要素同士の関係性

ルイージ要素 => 感情をゆさぶられる
工夫や上達でジレンマを乗りこなす

ルール インタラクション ジレンマ


ルールによる揺さぶり
恐怖 ×一定時間無敵化 → 喜び

インタラクションによる
安らぎ × 細い棒を落ちずに渡る →緊張

ジレンマによる
少リスク小リターン→大リスク大リターン

メタAI
アイテムの出現率いじったり 細い棒へ追い込む的 


AI
* オープンワールド
* プロシージャル

AIディレクター(メタAI


#### メタAIの設計
* オープンワールド
   * 順不同なアクセス
   * 広い地形とイベント密度
メタAIの調整でコストカット

   * プロシージャル
   * より高度なAIへの期待
メタAIの知識の集約

* サイドプレイしたくなるゲーム
* バランス調整

→メタAIが世界を認識する

WorldAnalyzer → GameMaker →WorldEffector

キャラクタAI 短時間で局所的
メタAI 長時間大局的

#### メタAI設計の解説

World側

KR InteractionSpace
Knowlegde representation
3Dゲームは複雑すぎる
ゲーム内の情報を人口知能があつかいやすい形にしたもの

ナビゲーションデータ
アフォーダンス
イベント表現
ヒートマップ
友好度

プレイヤー情報もKRとして扱う
プレイヤー感情
* 脳は
* スキンコンダクタンス
* アイトラッキングなど

InteractionSpace
* 作用空間
* AIの最終決定を反映させる空間
渡すKR  受け取るIS


メタAI world analyzer
分析で要素の候補が抽出される

GameMaker
ベストな演出プランを決定する

WorldEffector
プランを分解して指示を出す

デモ

#### 課題とまとめ
オープンワールドのコストカットが可能
キャラAIとメタAIの協調

緩急は可能 ただし起承転結はまだ難しい

- - -


## [人工知能学会×CEDECコラボセッション] 人工知能と対話システム ～キャラクターとの自然な会話～   もしくは展示みる
### 対話システムとは
対話とは
自然言語による情報授受 それにより自身外界に作用

複数のち的処理の統合

対話システムの種類
* タスク有無
* 人数
* モダリティ
* 主導権
* 身体制

タスク志向型
所定のタスクの遂行 レストラン検索など

以下のロジック
音声認識 発話理解 言語理解 対話状態 対話制御 発話生成 音声合成

スロットを埋める


非タスク志向
タスク遂行を主な目的にしない

メディアの等式


構成法
* ルールベース   商用だとほとんどこれ 
* 抽出ベース   twitterなどから情報をひっぱる
* 生成(深層学習)ベース    
* 理解･生成に基づく手法    ブログ・ツイッターから引っ張ってデータベースから抽出


### 対話感を高めるための技術
* ルールを作る
マッチすればよいが、ルールにない回答は無難な返答しかできない

似た文脈で現れる単語を列挙
質問文にいれて妥当性を確認 → ビッグデータで検証

* ビッグデータを使う
ツイッターの利用
ブログ

構造を分析しておく

* 個性をもつ
 キャラ語尾 など  ツイッターから文末表現を学習する

 キャラらしい発話の構成要素


 文末表


* 身体を持つ
* 意図を持つ
議論対話システム

### 対話システムの現状の課題
アノテーション
破綻ではない
破綻と言い切れないが違和感を感じる
あきらかにおかしい、破綻

だいたい20%くらいが破綻

alexa

### まとめ
ある程度の雑談はk脳なレベル

- - -

## スマホ版「ダビスタ」の操作テンポと開発スピードを上げたUIフレームワークの作り方

1画面内の操作量 増加
タッチ操作を活かして操作量を増やした

### UIフレームワーク実装背景
UI制作効率化と画面遷移制御が開発スピード向上
リリース時100を超える画面

フレームワークでやること

同時押し排他制御
通信時など タッチ制御
戻るボタン

チュートリアル
UIアニメーショントランジション
エラーポップアップ


→どのUIにおいても保証するUIフレームワークを作成
ほぼ1年で実装完了

クライアントエンジニア10人
共通してやるべきことをいかに意識しないか

UIレイアウトをツールでおこなってレイアウトデータの読み込みから画面上に反映させられるように

### エンジニアレベル実装
UI制作環境
cocos2dx 3

Unityでも同じことできる

レイアウトツール
cocos studio

デザイナーがcocosstudioでレイアウト構築
レイアウトファイルを出力 (Unityではprefab)
エンジニアが画面反映
インタラクション実装

### 設計思想
1scene制とレイヤー管理
レイヤーの生成と管理を主軸とした設計思想

レイヤー分割による操作性向上
レイヤー単位でリソース読み込み量分割、引き続きつかうレイヤーは読み込み直さない

### コードレベル
UIBase
レイヤーの管理

UICOntroller
UIBaseを管理するシングルトンクラス

UIのレイヤのグルーピング
main middle front dialog tutorial system

addFront
remove
replace

### レイヤーの重なりルール
画面ごとにレイヤーの表示とタッチのONOFF管理が必要
→各レイヤーは背面すべてのレイヤーに対して表示とタッチの有無を決める

レイヤは残す方針

### レイヤー実装方式
イベント駆動方式
UIControllerで各イベントを受け取って処理する

レイヤー疎結合制
レイヤーが他のレイヤーに対して処理しない

onLoaded

onRemove onBack

onClick onTouch

onEventDispatched
他のレイヤーにたいして通知


画面表示までの手軽さ
in out という名前でアニメーションをデザイナが仕込む

アンドロイドバックキー


複雑な繊維への耐魚
いろいろな画面から繊維できるように

フェード時にオンメモリキャッシュから削除している

### 通信処理実装の手軽さ

通信中レイヤーは通信1秒後にアニメーションを表示する

エラー処理の共通化
どの画面でも同じ


### チュートリアル

ゲーム中の画面繊維をそのまま使用しチュートリアル専用画面繊維は作っていない

luaで指定する

クリック待ち
文字列でクラスやレイヤを管理しているのでlua側からもマーシャリング不要で指定できる


プランナーが直接チュートリアルを作成できる。プランナーが普通にluaスクリプトで組める??

データ配信でチュートリアルをアプリ更新なしでチュートリアル改善が可能


### まとめ
レイヤー管理でリソース管理でのテンポ感向上、

QA
フレームワークの都合でできないってことはなかった
→あんまりなかった記憶

方針を決めるまで、ってどうだったか、もしくは他プロジェクトでやってたからできたか
→後者が大きい。前のプロジェクトでUnityで同じようなことをやっていたので

循環したらどうなる
→結果的に循環しなかった。大きなカテゴリを移動する場合は全部レイヤ消してる

通信まとめたりできるか
→queueでやってまとめられる

## ユーザを飽きさせない高頻度の更新を可能にする開発運用ノウハウ ～ハイスピードな開発、リリースを実現するために～

### 導入
#### ゲームにおける運用
コンテンツを追加し拡張していくこと

ゲームの面白さ + 定期的な更新

最高の運用
想像の上をいくクオリティとスピード感
不具合を出さない、常に安定稼働

→高頻度更新かつ不具合ゼロ

週に2~4回更新

課題
* 開発できるか
  * 開発用ツールを準備、拡張しやすい設計
* テストできるか
  * 
* リリースできるか
  * 高速ビルド 高速転送の整備
   
テストを効率化するシステムを構築する
→おもにデザインとパラメータが多い。ここを効率化する

デザイン素材検証
表示が正常か アニメーションが正常か 品質が適切か
→ 自動検証で担保するのはむずかしい

パラメータ検証
おかしな値になってえないか バランスがくずれてないか データ間での参照が適切か
→自動化できる

DSLによるメタプログラミングでチェックする仕組みの構築

### DSL
ドメイン固有言語

なぜDSL?
* データ制約の記述が適切
* 制約反映のフローが適切
* 検証以外の機能拡張

DSL 例
```
mastere(quest) {
    interger id;
    text name;
    integer reward_id;
    primary id;
    unique reward_id;
} >> where {
    if reward_id > 0
        unique_ref reward_id => iteem.id;
    end
    asseert { cost >= 10 }
    asseret { cost <= 20 }
}

master(item) {
    integer id;
    text name;
}

```

エラーが起きたら
社内連絡ツールにエラー情報を自動投稿

導入前後
前
Excel VBAでcsv生成
→ビルドと反映
→テスト

テスト段階でのエラー検出されるとビルドからやり直し

後
Excel VBAでcsv生成
→DSLデータ検証
→ビルドと反映
→テスト


どう普及させるか
開発フローで自然と触るように
→DSLからのコード生成、CSVデータのDB化 

DSL→生成プログラム(ruby)→DB

DSL→テーブル生成SQL生成→マスタデータDBにテーブル作成→CSVインポート

DB化によるメリット
起動時処理が高速化(CSV読むのが遅い)

マスタデータDBからのデータ取得や各カラム値取得に必要なコードをすべて作成

データクラス
データ管理クラス
統合管理クラス


自動生成の懸念
期間の概念など

自動生成 手動生成  partialで同名クラス


- - -

## バックエンドアーキテクチャ超変革 〜フルマネージドサービスを活用した管理コスト問題の解消〜

タイトルは増えるも人は増えない
管理コストを下げるしかない

### 現在の構成
オンプレに戻すのでAWSに極力依存しないように

RESTサーバ
Socketサーバ
DB Redis Memcache

### 問題解決
* オンプレにもどさなくてよくなった
* メンバーの経験たまった
* 多数の障害を経験して度胸がすわった

#### REST
ELB  Nodejs  express

問題
スケーリングが手動
* 前回イベントの状況みて手動でインスタンス数調整
* 頻繁にてがとられる
* 急なスパイクに対応できない

→
* スケーリング自動化必須
* ベンダーロックイン紀にしなくてよくなった

Lambda
* インスタンスなしで関数実行できる

api gateway
* HTTP リクエスト受け付ける
* フルマネージド  lambdaをキックする

serverless

しかしELB EC2とはあまりにも違いがあった

DBアクセス
* lambdaはVPCと切り離されてるのでVPCとは切り離されてる
* SGを設定しようにもインスタンスが固定でないのでIPが不定

→ lambdaをVPC上で起動するように設定することで回避

* lambdaはステートを保持しない
* 起動するたびにコネクション確立
→ コネクション死

解決
* dynamoDBに移行する ???
* DBはOKとしてRedisは?
* コードの修正


そもそもサーバーレス化が目的ではない、手段が目的化してはいけない


スケーリング自動化→ AutoScale
cloudwatchみて自動でイン・アウト
スピンアップタイムに不安

経験を活かす
* 計画的にスケールアップし、死品アップのリードタイムを稼ぐ。ピークタイムはわかってる



### Database
EC2 にCentOS mongodb

なぜmongo
* 当時のメンバーでは大規模な分散構成を自前でつくるのはきびしい


トランザクションがない
* ロジック側で一貫性を担保

同一DBなのに一部のテーブルだけ失敗する?
* ありえる
* そもそもシャードに分散されてる、アプリケーション側でわからない

ロジック側で対策できる、が複雑･冗長→mongoのパフォーマンスがでない

バックアップの問題
* バックアップソリューションのオーバーヘッドが大きかったためシャード別でバックアップ
* 結果時間ずれ
* OPログから復旧できるがつらい

容量単価が高い
* ディスク増やしてもメモリがボトルネックになる。結果シャードを増やすしかない
* サーバー増えて運用負荷あがる
* インフラ費もかかる


→AURORA
ただしmongoとのクエリの互換性がない
レコード形式の互換性ない
* 移行する必要がある

AWS DMS で解決

移行プラン
* DMS導入し、mongo → auroraへ移行
* 移行が完了しロジック側の対応が完了したテーブルから直近のメンテナンスで使用するDBを切り替えた
   * テーブル単位で切り替えdけいる
* しばらくmongoものこす。問題なければdms mongoを消す

ただし
* mongo 1カラムにでかいJSONだったりでエラーになったり
* 変換できても強引、クエリが複雑化


lambdaで変換

DMS
* データの変換ではなくJSONでs3に出力
* S3のputイベントでlambdaキック
* lambdaで変換してAuroraにインサート


### SOCKET
nodejs websocket socketio

バランシング
* インスタンスリストをRESTで共有
* インスタンスのルーム数もRESTで共有
* REESTがルームつくったら増減させる

スケーリング
* 自前スクリプトで
* 接続がなくなるまでまってイン

手間がかかる
* 手順が複雑･時間がかかる

バランシングがきれいに分散しない
* セッションをDBで管理
* mongo側のエラーで本来のセッション数とDBのセッション数がずれる

解決するために
* スケーリング自動化
* セッション管理を信頼性高く


SOCKETサーバのスケーリング自動化の難しさ
* セッション数を考慮したバランシング
* インスタンスを指定する仕組みが必要
* スケール員時に接続済みセッションを追い出す処理


GAMELIFT
* マルチプレイヤー専用ホスティングサービス

しかし
* C++ C#しかない
* エンドポイントをIPしかおしえてくれない

C#に移植した
* C#socketIO互換サーバー実装


IPでしか帰ってこない
* ドメインがないのでSSLが設定できない
* WebsocketはHTTP通信扱い ATSの対象
* ゲームサーバーのIPは不定

スケールアウト時
* ゲームサーバインスタンス起動時にシェルキックされる
* 自分のIPを取得
* Route53にレコード登録
* 登録完了まで待機
* Gameliftに準備完了を通知

イン時
* cloudwatchでlambda定期的にキック

* lambdaからgameliftのインスタンス


### 未来への取り組み

マイクロサービス化
* 他タイトルからも共有できるように

### まとめ
フルマネージドサービス コスト下げてクオリティ高められる


QA
dynamo mongo
→スキーマレス、移行は可能だがクエリがdynamoが貧弱 インデックス等も貼り直してリソースの管理がきびしい

gamelift問題はあるか
→gamelift起因の問題はない

